{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "97977abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from datasets import load_dataset\n",
    "import random\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    Seq2SeqTrainingArguments,\n",
    "    Seq2SeqTrainer\n",
    ")\n",
    "from rouge_score import rouge_scorer\n",
    "import warnings\n",
    "import torch\n",
    "import evaluate\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f4e3f0",
   "metadata": {},
   "source": [
    "## Fine-Tuning Methods for Language Models\n",
    "\n",
    "Fine-tuning a language model (LM) is a process of adapting a pre-trained model to a specific task or dataset. Here we discuss several methods for fine-tuning, each with its rationale, pros, cons, and typical use cases.\n",
    "\n",
    "### 1. Full Model Fine-Tuning\n",
    "\n",
    "#### Mathematical Formulation:\n",
    "$$ \\hat{\\theta} = \\arg\\min_{\\theta} \\{\\mathcal{L}(D_{\\text{finetune}}, \\theta)\\} $$\n",
    "where $\\hat{\\theta}$ are the updated model parameters, $\\mathcal{L}$ is a loss function such as cross-entropy on the fine-tuning dataset $D_{\\text{finetune}}$, and $\\theta$ are the original pre-trained parameters.\n",
    "\n",
    "#### Rationale:\n",
    "Fine-tuning the entire model adjusts all parameters on a downstream task, exploiting the pre-trained model as a starting point.\n",
    "\n",
    "#### Pros:\n",
    "- No need for manual architecture changes.\n",
    "- Tends to be very effective when transfer learning from related tasks.\n",
    "\n",
    "#### Cons:\n",
    "- Computationally expensive.\n",
    "- Risk of overfitting on small datasets.\n",
    "\n",
    "#### Typical Use Cases:\n",
    "- Supervised learning tasks with substantial labeled data.\n",
    "- Tasks closely related to the pre-training domain.\n",
    "\n",
    "### 2. Prompt Engineering\n",
    "\n",
    "Prompt engineering refers to techniques that involve formulating inputs to elicit desired behaviors from a pre-trained LM without modifying its parameters.\n",
    "\n",
    "#### Strata:\n",
    "\n",
    "  #### a. Few-shot Learning\n",
    "  Few-shot learning is a specific type of prompt engineering where the model is given a few examples to infer the task.\n",
    "\n",
    "  ##### Rationale:\n",
    "  By providing the LM with some examples, it can generalize and produce the correct output for similar tasks.\n",
    "\n",
    "  ##### Pros:\n",
    "  - Quick adaptation to tasks without parameter updates.\n",
    "  - Reduces data requirements for training.\n",
    "\n",
    "  ##### Cons:\n",
    "  - Performance depends heavily on quality and relevance of examples.\n",
    "  - Not all models generalize well from few examples.\n",
    "\n",
    "  ##### Typical Use Cases:\n",
    "  - Tasks where labeled data is scarce.\n",
    "  - Quick adaptation to new tasks where model re-training is infeasible.\n",
    "\n",
    "#### Pros:\n",
    "- No need to update parameters; computationally inexpensive.\n",
    "- Flexible and quick to implement for new tasks.\n",
    "\n",
    "#### Cons:\n",
    "- Finding effective prompts may require significant trial and error.\n",
    "- Less effective for tasks distant from pre-training domain.\n",
    "\n",
    "#### Typical Use Cases:\n",
    "- Zero-shot or few-shot tasks where training data is limited.\n",
    "- Exploratory data analysis and probing tasks.\n",
    "\n",
    "### 3. Layer-wise Over-parameterized Re-parameterization (LORA)\n",
    "\n",
    "#### Mathematical Formulation:\n",
    "In LORA, you introduce Δ A and Δ B such that the weight matrix W is re-parameterized by W' = W + ΔA ΔB.\n",
    "$$ h^{l+1} = \\phi(W' h^{l} + b^{l}) $$\n",
    "\n",
    "#### Rationale:\n",
    "LORA adds low-rank modifications to the weights of the pre-trained model, enabling fine-tuning with fewer parameters and computational overhead.\n",
    "\n",
    "#### Pros:\n",
    "- Efficient parameter updates.\n",
    "- Can retain the general knowledge of the pre-trained model.\n",
    "\n",
    "#### Cons:\n",
    "- May not perform as well as full model fine-tuning in some cases.\n",
    "- Slightly increased model complexity due to additional parameters.\n",
    "\n",
    "#### Typical Use Cases:\n",
    "- Situations with limited computational budgets and training time.\n",
    "- Scenarios where retaining the original model parameters is critical.\n",
    "\n",
    "### 4. Transfer Learning with Adapter Layers\n",
    "\n",
    "#### Mathematical Formulation:\n",
    "Adapter layers introduce task-specific parameters A such that they transform the intermediate representation H.\n",
    "$$ H_{\\text{adapter}} = \\sigma(H W_{\\text{down}})W_{\\text{up}} $$\n",
    "where $\\sigma$ is a non-linear activation function, and $W_{\\text{down}}$, $W_{\\text{up}}$ are the learnable parameters of the adapter layer.\n",
    "\n",
    "#### Rationale:\n",
    "Adapters allow the model to adapt to a new task by learning a small set of task-specific parameters inserted between the pre-trained layers.\n",
    "\n",
    "#### Pros:\n",
    "- Task-specific fine-tuning without altering the original model parameters.\n",
    "- More parameter-efficient than full fine-tuning.\n",
    "\n",
    "#### Cons:\n",
    "- May not reach the same performance as full fine-tuning for every task.\n",
    "- Introduces additional hyperparameters to tune (e.g., adapter size).\n",
    "\n",
    "#### Typical Use Cases:\n",
    "- Multi-task learning where each task requires specific adaptations.\n",
    "- Scenarios that need to preserve the original model weights for multiple purposes.\n",
    "\n",
    "### 5. Reinforcement Learning from Human Feedback (RLHF)\n",
    "\n",
    "#### Mathematical Formulation:\n",
    "$$ \\theta^* = \\arg\\max_{\\theta} \\mathbb{E}_{\\pi_{\\theta}(a|s)} [R(s, a)] $$\n",
    "where $R(s, a)$ is a reward function typically derived from human feedback, and $\\pi_{\\theta}(a|s)$ is the policy (e.g., the LM's predictions) parameterized by $\\theta$.\n",
    "\n",
    "#### Rationale:\n",
    "RLHF directly optimizes the LM's outputs towards behaviors that receive higher rewards according to human preferences.\n",
    "\n",
    "#### Pros:\n",
    "- Aligns fine-tuning with human values and preferences.\n",
    "- Can improve specific aspects of model behavior.\n",
    "\n",
    "#### Cons:\n",
    "- Human feedback can be expensive and time-consuming to collect.\n",
    "- Risk of reward hacking, where the model learns shortcuts to gain rewards.\n",
    "\n",
    "#### Typical Use Cases:\n",
    "- Tasks that require subjective quality judgments (e.g., content generation, dialogue systems).\n",
    "- Scenarios where ethical or safety considerations are paramount.\n",
    "\n",
    "By selecting the appropriate fine-tuning method, one can tailor a pre-trained LM to a wide range of tasks and use cases with varying requirements and constraints."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408280e4",
   "metadata": {},
   "source": [
    "## Types of Fine-Tuning Tasks for Language Models\n",
    "\n",
    "Fine-tuning tasks are specific challenges or objectives used to adapt a pre-trained Language Model (LM) to perform better on certain types of data or problems. Below are some common fine-tuning tasks and their associated loss functions.\n",
    "\n",
    "### 1. Text Classification\n",
    "\n",
    "#### Loss Function:\n",
    "Cross-Entropy Loss\n",
    "$$ \\mathcal{L}(\\theta) = -\\sum_{(x, y) \\in D} \\log p_\\theta(y | x) $$\n",
    "where $D$ is the dataset containing text inputs $x$ and labels $y$, and $p_\\theta(y | x)$ is the probability assigned by the model with parameters $\\theta$ to the correct label $y$ given input $x$.\n",
    "\n",
    "### 2. Named Entity Recognition (NER)\n",
    "\n",
    "#### Loss Function:\n",
    "Conditional Random Field (CRF) (for sequence labeling)\n",
    "$$ \\mathcal{L}(\\theta) = -\\sum_{(x, \\mathbf{y}) \\in D} \\log p_\\theta(\\mathbf{y} | x) $$\n",
    "where $D$ is the dataset of sequences $x$ with corresponding entity label sequences $\\mathbf{y}$, and $p_\\theta(\\mathbf{y} | x)$ is the conditional probability given by the model with parameters $\\theta$ to the correct label sequence $\\mathbf{y}$.\n",
    "\n",
    "### 3. Language Generation\n",
    "\n",
    "#### Loss Function:\n",
    "Negative Log-Likelihood Loss\n",
    "$$ \\mathcal{L}(\\theta) = -\\sum_{(x, y) \\in D} \\sum_{t} \\log p_\\theta(y_t | y_{<t}, x) $$\n",
    "where $D$ is the dataset of input-output pairs $(x, y)$, $y_t$ is the $t$-th token in the output sequence $y$, and $y_{<t}$ represents the sequence of tokens before $y_t$. The loss sums over all tokens in the output sequence.\n",
    "\n",
    "### 4. Machine Translation\n",
    "\n",
    "#### Loss Function:\n",
    "Sequence-to-sequence Loss (typically cross-entropy)\n",
    "$$ \\mathcal{L}(\\theta) = -\\sum_{(x, y) \\in D} \\log p_\\theta(y | x) $$\n",
    "where $D$ is the dataset of source-target pairs $(x, y)$, $y$ is the translated sequence, and $p_\\theta(y | x)$ is the probability assigned by the model with parameters $\\theta$ to the translation $y$ given source $x$.\n",
    "\n",
    "### 5. Question Answering\n",
    "\n",
    "#### Loss Function:\n",
    "Span Prediction Loss (combination of start and end token cross-entropy)\n",
    "$$ \\mathcal{L}(\\theta) = -\\sum_{(x, y_{start}, y_{end}) \\in D} (\\log p_\\theta(y_{start} | x) + \\log p_\\theta(y_{end} | x)) $$\n",
    "where $D$ is the dataset of contexts $x$ with corresponding answer start and end positions $y_{start}, y_{end}$, and $p_\\theta(y_{start} | x)$, $p_\\theta(y_{end} | x)$ are the probabilities assigned to the start and end positions of the answer span.\n",
    "\n",
    "### 6. Sentiment Analysis\n",
    "\n",
    "#### Loss Function:\n",
    "Cross-Entropy Loss\n",
    "$$ \\mathcal{L}(\\theta) = -\\sum_{(x, y) \\in D} \\log p_\\theta(y | x) $$\n",
    "where $D$ is the dataset containing text inputs $x$ and sentiment labels $y$, and $p_\\theta(y | x)$ is the probability that the model with parameters $\\theta$ assigns to the correct sentiment label $y$ given input $x$.\n",
    "\n",
    "### 7. Summarization\n",
    "\n",
    "#### Loss Function:\n",
    "Negative Log-Likelihood Loss for Sequence Generation\n",
    "$$ \\mathcal{L}(\\theta) = -\\sum_{(x, y) \\in D} \\sum_{t} \\log p_\\theta(y_t | y_{<t}, x) $$\n",
    "where $D$ is the dataset of document-summary pairs $(x, y)$, and the loss is calculated over the output summary tokens $y_{t}$ given the document $x$ and previous tokens $y_{<t}$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f972fdf2",
   "metadata": {},
   "source": [
    "## Fine-Tuning on Multiple Tasks\n",
    "\n",
    "Fine-tuning a Language Model on multiple tasks is an important approach to build versatile systems that can handle various types of language processing jobs. Here are the most common strategies for multi-task learning and fine-tuning:\n",
    "\n",
    "### Sequential Fine-Tuning\n",
    "\n",
    "In sequential fine-tuning, models are first fine-tuned on one task and then subsequently fine-tuned on another. This can potentially lead to catastrophic forgetting, but is a simple approach to adapt models to new tasks based on a common foundation.\n",
    "\n",
    "### Multi-Task Learning\n",
    "\n",
    "A model is fine-tuned on multiple tasks simultaneously. This often involves shared representations for all tasks, and sometimes task-specific heads or layers. This approach is designed to help the model generalize better across tasks and leverage shared knowledge.\n",
    "\n",
    "### Continual Learning\n",
    "\n",
    "This approach focuses on fine-tuning a model across a sequence of tasks while retaining the ability to perform well on previous tasks. Techniques include replaying data from previous tasks or using regularization strategies to protect previous knowledge.\n",
    "\n",
    "### Adapters\n",
    "\n",
    "Fine-tuning through adapter modules involves adding small, task-specific modules to a pre-trained model without altering its weights. Each task's learning is compartmentalized, allowing the model to tackle multiple tasks effectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b51282b",
   "metadata": {},
   "source": [
    "## Load and sub-sample dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3fac2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a small text summarization public dataset\n",
    "dataset = load_dataset(\"xsum\")\n",
    "\n",
    "# Subsample to 100 examples\n",
    "subsampled_dataset = dataset['train'].shuffle(seed=42).select(range(100))\n",
    "\n",
    "model_name = 't5-small'\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"t5-small\")\n",
    "\n",
    "# Tokenization function with padding and truncation\n",
    "def tokenize_function(examples):\n",
    "    # Tokenize the texts and include padding and truncation to a fixed length\n",
    "    model_inputs = tokenizer(examples[\"document\"], padding=\"max_length\", truncation=True, max_length=512)\n",
    "    # Perform the same steps for the summaries (labels)\n",
    "    # The summaries are trimmed/padded to a smaller max length to allow for faster training\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(examples[\"summary\"], padding=\"max_length\", truncation=True, max_length=128)\n",
    "    \n",
    "    # PyTorch expects -100 for ignored indices (e.g., padding) in the labels for sequence-to-sequence models\n",
    "    labels[\"input_ids\"] = [\n",
    "        [(label if label != tokenizer.pad_token_id else -100) for label in label_input]\n",
    "        for label_input in labels[\"input_ids\"]\n",
    "    ]\n",
    "    \n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "# Tokenize the dataset\n",
    "tokenized_datasets = subsampled_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# Prepare the dataset for the trainer\n",
    "small_train_dataset = tokenized_datasets.shuffle(seed=42).select(range(80)) # 80 for training\n",
    "small_eval_dataset = tokenized_datasets.shuffle(seed=42).select(range(80, 100)) # 20 for evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89a8c540",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['document', 'summary', 'id', 'input_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 20\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_eval_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b825e5d7",
   "metadata": {},
   "source": [
    "## Define finetuning function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dd86e8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model):\n",
    "    # Define training arguments\n",
    "    training_args = Seq2SeqTrainingArguments(\n",
    "        output_dir=\"./results\",\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        learning_rate=2e-5,\n",
    "        per_device_train_batch_size=4,\n",
    "        per_device_eval_batch_size=4,\n",
    "        weight_decay=0.01,\n",
    "        save_total_limit=2,\n",
    "        num_train_epochs=2,\n",
    "        predict_with_generate=True\n",
    "    )\n",
    "    \n",
    "    # Instantiate the Trainer\n",
    "    trainer = Seq2SeqTrainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=small_train_dataset,\n",
    "        eval_dataset=small_eval_dataset,\n",
    "        tokenizer=tokenizer\n",
    "    )\n",
    "    \n",
    "    # Train the model\n",
    "    trainer.train()\n",
    "    \n",
    "    # Return the trained model\n",
    "    return trainer.model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3562014",
   "metadata": {},
   "source": [
    "### Finetune model using different methods "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "81fba756",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "WARNING:accelerate.utils.other:Detected kernel version 4.14.262, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='40' max='40' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [40/40 00:12, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>3.816803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>3.717122</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Full fine-tuning\n",
    "pretrained_model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "full_finetuned_model = train_model(pretrained_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70e9ab4",
   "metadata": {},
   "source": [
    "## Define evaluation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "86664a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, tokenizer, dataset, device='cuda'):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    rouge_metric = evaluate.load('rouge')\n",
    "    generated_texts = []\n",
    "    references = []\n",
    "    \n",
    "    for example in dataset:\n",
    "        input_text = example['document']\n",
    "        reference = example['summary']\n",
    "        \n",
    "        inputs = tokenizer(input_text, return_tensors='pt', max_length=1024, truncation=True)\n",
    "        inputs = inputs.to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            summary_ids = model.generate(inputs[\"input_ids\"], max_length=150, min_length=40, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
    "        \n",
    "        generated_summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "        \n",
    "        generated_texts.append(generated_summary)\n",
    "        references.append(reference)\n",
    "    \n",
    "    # Compute ROUGE scores for all generated texts\n",
    "    # Note that references are expected to be lists of lists of strings for 'rouge'\n",
    "    rouge_results = rouge_metric.compute(predictions=generated_texts, references=[[r] for r in references])\n",
    "    \n",
    "    # Process result: Extract the metrics' means\n",
    "    processed_results = {}\n",
    "    for key in rouge_results.keys():\n",
    "        metric_scores = rouge_results[key]\n",
    "        if isinstance(metric_scores, dict):\n",
    "            # When metrics return a dict with 'precision', 'recall', and 'fmeasure'\n",
    "            processed_results[key] = metric_scores['fmeasure'] * 100\n",
    "        else:\n",
    "            # When metrics return direct scores (e.g., floats)\n",
    "            processed_results[key] = metric_scores * 100\n",
    "    \n",
    "    return processed_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c92ba3",
   "metadata": {},
   "source": [
    "## Evaluate full and base model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3bf53caa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge1': 20.43459827021852, 'rouge2': 2.743339231408865, 'rougeL': 13.54311808719664, 'rougeLsum': 13.524231259552256}\n"
     ]
    }
   ],
   "source": [
    "# Assuming you have a model, tokenizer, and small_eval_dataset defined and loaded appropriately\n",
    "rouge_scores = evaluate_model(full_finetuned_model, tokenizer, small_eval_dataset)\n",
    "print(rouge_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c5254da4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge1': 20.43459827021852, 'rouge2': 2.743339231408865, 'rougeL': 13.54311808719664, 'rougeLsum': 13.524231259552256}\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "# Assuming you have a model, tokenizer, and small_eval_dataset defined and loaded appropriately\n",
    "rouge_scores = evaluate_model(pretrained_model, tokenizer, small_eval_dataset)\n",
    "print(rouge_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3147d1ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_env_python",
   "language": "python",
   "name": "llm_env_python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
